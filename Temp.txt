Below is a worked-through blueprint for a UV-managed Python monorepo that now contains several reusable libraries (packages) and ~10 deployable apps.  You can copy-paste the snippets as-is and adapt names/versions later.


---

1 Repository layout

repo-root/
│
├── pyproject.toml          # ← workspace root (not published)
├── uv.lock                 # single, deterministic lockfile
│
├── packages/               # shared libraries
│   ├── common/
│   │   ├── pyproject.toml
│   │   └── src/myco_common/…
│   └── data_models/
│       ├── pyproject.toml
│       └── src/myco_data_models/…
│
├── apps/                   # runnable deliverables
│   ├── ingestion/
│   │   ├── pyproject.toml
│   │   └── src/ingest_app/__main__.py
│   ├── reporting/
│   │   └── …
│   └── … eight more …
│
├── configs/                # YAML, JSON, env files
├── scripts/                # tiny helper shell/Python scripts
└── .gitlab-ci.yml

Why this works

src/ layout keeps import paths predictable.

Each package/app is an independent PEP 621 project so you can publish or test it alone, but the workspace gives you one lockfile and one virtualenv to keep versions consistent (a Cargo-style approach). 



---

2 Root pyproject.toml

[project]
name = "myco-workspace"      # not published – just a placeholder
version = "0.0.0"
description = "Internal workspace root"
readme = "README.md"
requires-python = ">=3.12"

[tool.uv.workspace]
# Everything listed here is part of the workspace → gets an editable install
members = [
    "packages/common",
    "packages/data_models",
    "apps/ingestion",
    "apps/reporting",
    # … add the rest …
]

[build-system]
requires = ["hatchling>=1.24"]
build-backend = "hatchling.build"

Notes

tool.uv.workspace is the only line that turns the repo into a workspace – no extra tooling needed. 

Root itself has no code; that’s fine – UV will still create .venv + uv.lock.



---

3 Example library package – packages/common/pyproject.toml

[project]
name            = "myco-common"
version         = "0.3.1"
description     = "Shared helpers, logging, small utilities"
requires-python = ">=3.12"
dependencies    = [
    "pydantic>=2.6",
    "loguru>=0.7",
]

[project.optional-dependencies]
test = ["pytest", "coverage[toml]"]
dev  = ["ruff", "mypy"]

[build-system]
requires = ["hatchling>=1.24"]
build-backend = "hatchling.build"

Tests live at packages/common/tests/ and run under the same workspace venv.


---

4 Example app package – apps/ingestion/pyproject.toml

[project]
name            = "ingestion-app"
version         = "1.2.0"
description     = "Batch & streaming ingestion service"
requires-python = ">=3.12"
dependencies    = [
    # internal workspace libs:
    "myco-common",            # ← resolves locally, no version pin needed
    "myco-data-models",
    # external:
    "pandas>=2.2",
    "pyyaml>=6",
    "boto3>=1.34",
]

[project.scripts]
ingest = "ingest_app.cli:main"   # uv run ingest …

[build-system]
requires = ["hatchling>=1.24"]
build-backend = "hatchling.build"

Because the workspace environment installs every member editable, local changes show up immediately during development. 


---

5 Typical developer workflow

# one-time clone
git clone git@gitlab.com:myco/data-platform.git && cd data-platform

# initialise env + install everything (first sync)
uv sync --all-packages          # or simply `uv sync` from repo root
uv run ingest --help            # runs entry point from apps/ingestion
uv run pytest -q                # tests across the whole workspace
# add a dependency to a sub-project
cd packages/common
uv add rich
# regenerate deterministic lockfile
uv lock                          # locks the whole workspace
git add uv.lock && git commit -m "feat: rich in common"

--all-packages installs every member into .venv; omit it if you want a lighter-weight env just for the one you’re editing. 


---

6 GitLab CI (.gitlab-ci.yml)

image: python:3.12-slim

stages: [lint, test, build]

variables:
  PIP_DISABLE_PIP_VERSION_CHECK: "1"
  UV_CACHE_DIR: "$CI_PROJECT_DIR/.cache/uv"  # speeds up repeated installs

cache:
  key: ${CI_PROJECT_PATH_SLUG}-uv
  paths:
    - .cache/uv
    - .venv             # re-use the workspace venv across stages

before_script:
  - pip install --upgrade uv
  # install optional dev deps (ruff/pytest/coverage) from root extra group
  - uv sync --all-packages --group dev,test

lint:
  stage: lint
  script:
    - uv run ruff check .

test:
  stage: test
  needs: [lint]
  script:
    - uv run coverage run -m pytest
    - uv run coverage xml
  artifacts:
    reports:
      cobertura: coverage.xml

build:
  stage: build
  needs: [test]
  script:
    - uv build --sdist --wheel --out dist/
  artifacts:
    paths:
      - dist/

What this does

Uses a single cached .venv for all jobs → faster pipelines.

uv sync installs the entire workspace once, in editable mode.

For real releases you can add a publish stage that pushes wheels to GitLab Package Registry or PyPI via uv publish.



---

7 Pro tips & patterns

Need	Suggestion

Consistent version bumps across all 10 apps	Use semantic-release or hatch version in the root job; tag once, update every member’s version.
Isolated container builds	In each Dockerfile: COPY ./uv.lock ./ and RUN uv sync --all-packages --no-editable --no-dev.
Code ownership	Put a CODEOWNERS file per top-level folder (packages/*, apps/*) so merge requests auto-tag correct reviewers.
Typed public API	Keep the shared packages fully type-checked (Mypy strict), apps can be more relaxed.
Gradual migration	You can leave legacy “loose” scripts under scripts/ – as they stabilise, promote them to apps/….



---

Recap

Workspace root + member pyproject.toml gives you one lockfile, one venv.

UV commands (sync, lock, run) work on the whole repo or a single package with --package.

GitLab CI becomes extremely small – no need for Poetry or pip-tools, just uv.


With this structure you can keep scaling the monorepo without losing dependency sanity or CI speed. Happy hacking!




What is a UV workspace?

“A workspace is a collection of one or more packages, called workspace members, that are managed together.” 
In practice that means:

Concept	Effect in day-to-day work

One lock-file (uv.lock)	All members resolve to the same dependency graph, eliminating “works on my app but not on yours”. 
One virtual-env (.venv)	uv sync installs every member editable into that env, so edits are visible everywhere immediately.
One Python version	UV intersects the requires-python spec of every member; if they disagree the lock will fail. 
Many pyproject.tomls	Each package or app declares its own name, version, dependencies, entry points, etc.
Cargo-style CLI	uv run, uv sync, uvx <tool> default to the workspace root but accept --package foo to target a single member. 



---

How does UV know a repo is a workspace?

Add two tables to the root pyproject.toml:

[tool.uv.workspace]         # ① declares “this is a workspace”
members  = ["packages/*", "apps/*"]
exclude  = ["packages/legacy_*"]   # optional glob patterns

[tool.uv.sources]           # ② tells uv that some deps come *from* the workspace
common-utils = { workspace = true }

Every directory matched by members must contain its own pyproject.toml.

Anything excluded is ignored even if it has a project file. 

workspace = true means “satisfy this requirement with the editable copy that lives in the repo; don’t fetch it from PyPI.” 



---

Typical commands

Task	Command	What happens

Create env + install everything	uv sync --all-packages	Installs every member editable plus its external deps.
Add a new dep to one member	cd packages/common && uv add rich	Updates that member’s pyproject.toml; run uv lock to refresh the workspace graph.
Run a script in another member	uv run --package ingestion ingest --help	Executes inside the shared .venv, but sets PYTHONPATH so ingestion is the active project.
Freeze deps	uv lock	Re-solves entire workspace and rewrites uv.lock.
Build & publish just one app	uv build --package reporting then uv publish --package reporting	Generates wheel/sdist for that member only, still using the workspace lockfile.



---

When workspaces shine … and when they don’t

Great for

Mono-repos that mix multiple libraries + a few services (your case exactly).

Teams that want one CI pipeline and consistent dependency resolution.

Fast local DX – no more juggling 10 virtual-envs.


Not ideal if

Members truly need conflicting library versions.

You must test one member on Py-3.9 while others are 3.12 (the single-Python rule blocks this). 

You want hard isolation of transitive imports – UV can’t stop package-A from import sqlalchemy even if only package-B declared it. 
Use separate repos or plain path = "..." dependencies instead. 



---

Quick mental model

┌───────────────────────────────┐
│  Workspace root               │  ← has its own project definition
│  - pyproject.toml   (① + ②)   │
│  - uv.lock (one per repo)     │
│  - .venv/ (one per repo)      │
│                               │
│  members/                     │
│  ├── lib_a/pyproject.toml     │  ← library
│  ├── lib_b/pyproject.toml     │  ← library
│  └── app_ingest/pyproject.toml│  ← runnable service
└───────────────────────────────┘

Think of the workspace root as a meta-package that happens to own the lockfile and the virtual-env.


---

Cheat-sheet for your team

# setup
git clone … && cd repo
uv sync --all-packages

# everyday hacking
uv run pytest -q        # tests entire workspace
uv run --package lib_a pytest tests
uv add --package app_ingest fastapi[all]
uv lock                 # regenerate lock

# CI
uv sync --all-packages --group dev,test
uv run ruff check .
uv run coverage run -m pytest


---

TL;DR

UV workspaces give you Cargo-like project orchestration for Python: one lockfile, one env, many packages – perfect for a monorepo of shared libraries and ~10 business apps. Define tool.uv.workspace + tool.uv.sources once, and UV handles the rest.

